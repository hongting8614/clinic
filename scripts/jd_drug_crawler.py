#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº¬ä¸œåŒ»è¯æ•°æ®çˆ¬è™«
çˆ¬å–è¯æä¿¡æ¯ï¼šæ¡å½¢ç ã€è¯åã€è§„æ ¼ã€å•ä½ã€å‚å®¶ç­‰
"""

import time
import json
import re
import csv
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

class JDDrugCrawler:
    def __init__(self):
        # é…ç½®Chromeé€‰é¡¹
        chrome_options = Options()
        # chrome_options.add_argument('--headless')  # æ— å¤´æ¨¡å¼ï¼ˆå¯é€‰ï¼‰
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # åˆå§‹åŒ–æµè§ˆå™¨
        print("ğŸš€ å¯åŠ¨æµè§ˆå™¨...")
        from selenium.webdriver.chrome.service import Service
        
        # ä½¿ç”¨ç³»ç»ŸPATHä¸­çš„ChromeDriver
        try:
            self.driver = webdriver.Chrome(
                service=Service(),
                options=chrome_options
            )
        except Exception as e:
            print(f"âš ï¸ å¯åŠ¨å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹å¼...")
            # å¤‡ç”¨æ–¹å¼ï¼šä¸æŒ‡å®šservice
            chrome_options.add_argument('--disable-gpu')
            self.driver = webdriver.Chrome(options=chrome_options)
        self.wait = WebDriverWait(self.driver, 10)
        
        # æ•°æ®å­˜å‚¨
        self.drugs = []
        
    def search_drugs(self, keyword="æ„Ÿå†’è¯", max_pages=3):
        """
        æœç´¢è¯æ
        """
        print(f"\nğŸ” æœç´¢å…³é”®è¯: {keyword}")
        
        # äº¬ä¸œæœç´¢URL
        url = f"https://search.jd.com/Search?keyword={keyword}&enc=utf-8"
        print(f"ğŸ“¡ è®¿é—®: {url}")
        
        self.driver.get(url)
        print("â³ ç­‰å¾…é¡µé¢åŠ è½½...")
        time.sleep(5)  # å¢åŠ ç­‰å¾…æ—¶é—´
        
        # è°ƒè¯•ï¼šä¿å­˜é¡µé¢æˆªå›¾
        try:
            self.driver.save_screenshot('debug_page.png')
            print("ğŸ“¸ é¡µé¢æˆªå›¾å·²ä¿å­˜: debug_page.png")
        except:
            pass
        
        for page in range(1, max_pages + 1):
            print(f"\nğŸ“„ ç¬¬ {page} é¡µ")
            
            # å°è¯•å¤šç§é€‰æ‹©å™¨æŸ¥æ‰¾å•†å“åˆ—è¡¨
            print("ğŸ” æŸ¥æ‰¾å•†å“åˆ—è¡¨...")
            items = []
            
            # æ–¹æ³•1ï¼šæ ‡å‡†å•†å“åˆ—è¡¨
            try:
                items = self.driver.find_elements(By.CSS_SELECTOR, '#J_goodsList .gl-item')
                if items:
                    print(f"âœ… æ–¹æ³•1æˆåŠŸï¼Œæ‰¾åˆ° {len(items)} ä¸ªå•†å“")
            except:
                pass
            
            # æ–¹æ³•2ï¼šå¤‡ç”¨é€‰æ‹©å™¨
            if not items:
                try:
                    items = self.driver.find_elements(By.CLASS_NAME, 'gl-item')
                    if items:
                        print(f"âœ… æ–¹æ³•2æˆåŠŸï¼Œæ‰¾åˆ° {len(items)} ä¸ªå•†å“")
                except:
                    pass
            
            # æ–¹æ³•3ï¼šé€šç”¨å•†å“å¡ç‰‡
            if not items:
                try:
                    items = self.driver.find_elements(By.CSS_SELECTOR, '.goods-item')
                    if items:
                        print(f"âœ… æ–¹æ³•3æˆåŠŸï¼Œæ‰¾åˆ° {len(items)} ä¸ªå•†å“")
                except:
                    pass
            
            if not items:
                print("âŒ æœªæ‰¾åˆ°å•†å“åˆ—è¡¨")
                print("ğŸ’¡ å¯èƒ½åŸå› ï¼š")
                print("   1. äº¬ä¸œé¡µé¢ç»“æ„å˜åŒ–")
                print("   2. éœ€è¦ç™»å½•æˆ–éªŒè¯")
                print("   3. åçˆ¬è™«æœºåˆ¶")
                print(f"   4. å½“å‰URL: {self.driver.current_url}")
                break
            
            # æå–å•†å“ä¿¡æ¯
            for i, item in enumerate(items):
                try:
                    # æå–å•†å“ä¿¡æ¯
                    drug_info = self.extract_item_info(item)
                    if drug_info:
                        print(f"  [{i+1}] âœ… {drug_info['name']}")
                        self.drugs.append(drug_info)
                    
                    time.sleep(0.5)  # å»¶è¿Ÿ
                    
                except Exception as e:
                    print(f"  [{i+1}] âŒ æå–å¤±è´¥: {str(e)}")
            
            # ç¿»é¡µ
            if page < max_pages:
                try:
                    next_btn = self.driver.find_element(By.CLASS_NAME, 'pn-next')
                    next_btn.click()
                    time.sleep(2)
                except:
                    print("âŒ æ— æ³•ç¿»é¡µ")
                    break
        
        print(f"\nâœ… æœç´¢å®Œæˆï¼Œå…±é‡‡é›† {len(self.drugs)} æ¡æ•°æ®")
    
    def extract_item_info(self, item):
        """
        ä»å•†å“é¡¹æå–ä¿¡æ¯
        """
        try:
            # å•†å“åç§°
            name_elem = item.find_element(By.CSS_SELECTOR, '.p-name em')
            name = name_elem.text.strip()
            
            # å•†å“é“¾æ¥
            link_elem = item.find_element(By.CSS_SELECTOR, '.p-name a')
            link = link_elem.get_attribute('href')
            
            # å•†å“ID
            sku_id = item.get_attribute('data-sku')
            
            # ä»·æ ¼
            try:
                price_elem = item.find_element(By.CSS_SELECTOR, '.p-price i')
                price = price_elem.text.strip()
            except:
                price = ''
            
            # åº—é“º
            try:
                shop_elem = item.find_element(By.CSS_SELECTOR, '.p-shop a')
                shop = shop_elem.text.strip()
            except:
                shop = ''
            
            return {
                'skuId': sku_id,
                'name': name,
                'link': link,
                'price': price,
                'shop': shop,
                'barcode': '',  # éœ€è¦è¿›å…¥è¯¦æƒ…é¡µè·å–
                'specification': '',
                'manufacturer': '',
                'approvalNumber': ''
            }
            
        except Exception as e:
            print(f"æå–å¤±è´¥: {str(e)}")
            return None
    
    def get_drug_detail(self, drug_info):
        """
        è·å–è¯æè¯¦æƒ…ï¼ˆåŒ…æ‹¬æ¡å½¢ç ï¼‰
        """
        print(f"\nğŸ“‹ è·å–è¯¦æƒ…: {drug_info['name']}")
        
        try:
            # è®¿é—®å•†å“è¯¦æƒ…é¡µ
            self.driver.get(drug_info['link'])
            time.sleep(3)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'product-intro')))
            
            # è·å–é¡µé¢HTML
            html = self.driver.page_source
            soup = BeautifulSoup(html, 'html.parser')
            
            # æå–å•†å“è§„æ ¼
            spec_div = soup.find('div', {'id': 'parameter-brand'})
            if spec_div:
                params = spec_div.find_all('li')
                for param in params:
                    text = param.get_text()
                    
                    # æ¡å½¢ç 
                    if 'æ¡å½¢ç ' in text or 'å•†å“ç¼–ç ' in text:
                        barcode = text.split('ï¼š')[-1].strip()
                        drug_info['barcode'] = barcode
                    
                    # è§„æ ¼
                    if 'è§„æ ¼' in text:
                        spec = text.split('ï¼š')[-1].strip()
                        drug_info['specification'] = spec
                    
                    # ç”Ÿäº§ä¼ä¸š
                    if 'ç”Ÿäº§ä¼ä¸š' in text or 'å‚å®¶' in text:
                        manufacturer = text.split('ï¼š')[-1].strip()
                        drug_info['manufacturer'] = manufacturer
                    
                    # æ‰¹å‡†æ–‡å·
                    if 'æ‰¹å‡†æ–‡å·' in text:
                        approval = text.split('ï¼š')[-1].strip()
                        drug_info['approvalNumber'] = approval
            
            # æå–å•ä½ï¼ˆä»è§„æ ¼ä¸­æ¨æ–­ï¼‰
            unit = self.parse_unit(drug_info.get('specification', ''))
            drug_info['unit'] = unit
            
            print(f"  âœ… æ¡å½¢ç : {drug_info.get('barcode', 'æœªæ‰¾åˆ°')}")
            print(f"  âœ… è§„æ ¼: {drug_info.get('specification', 'æœªæ‰¾åˆ°')}")
            print(f"  âœ… å‚å®¶: {drug_info.get('manufacturer', 'æœªæ‰¾åˆ°')}")
            
            return True
            
        except Exception as e:
            print(f"  âŒ è·å–è¯¦æƒ…å¤±è´¥: {str(e)}")
            return False
    
    def parse_unit(self, specification):
        """
        ä»è§„æ ¼ä¸­è§£æå•ä½
        """
        if 'ç›’' in specification:
            return 'ç›’'
        elif 'ç“¶' in specification:
            return 'ç“¶'
        elif 'æ”¯' in specification:
            return 'æ”¯'
        elif 'è¢‹' in specification:
            return 'è¢‹'
        else:
            return 'ç›’'
    
    def batch_get_details(self):
        """
        æ‰¹é‡è·å–è¯¦æƒ…
        """
        print(f"\nğŸ“‹ æ‰¹é‡è·å–è¯¦æƒ…ï¼Œå…± {len(self.drugs)} æ¡")
        
        for i, drug in enumerate(self.drugs):
            print(f"\n[{i+1}/{len(self.drugs)}]")
            
            self.get_drug_detail(drug)
            
            # å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(2)
    
    def save_to_csv(self, filename='äº¬ä¸œè¯ææ•°æ®.csv'):
        """
        ä¿å­˜ä¸ºCSV
        """
        if not self.drugs:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
        
        print(f"\nğŸ’¾ ä¿å­˜åˆ°: {filename}")
        
        df = pd.DataFrame(self.drugs)
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        
        print(f"âœ… ä¿å­˜æˆåŠŸï¼Œå…± {len(self.drugs)} æ¡è®°å½•")
    
    def save_to_excel(self, filename='äº¬ä¸œè¯ææ•°æ®.xlsx'):
        """
        ä¿å­˜ä¸ºExcel
        """
        if not self.drugs:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
        
        print(f"\nğŸ’¾ ä¿å­˜åˆ°: {filename}")
        
        df = pd.DataFrame(self.drugs)
        df.to_excel(filename, index=False, engine='openpyxl')
        
        print(f"âœ… ä¿å­˜æˆåŠŸï¼Œå…± {len(self.drugs)} æ¡è®°å½•")
    
    def generate_import_script(self, filename='å¯¼å…¥äº¬ä¸œæ•°æ®.js'):
        """
        ç”Ÿæˆäº‘æ•°æ®åº“å¯¼å…¥è„šæœ¬
        """
        if not self.drugs:
            print("âŒ æ²¡æœ‰æ•°æ®")
            return
        
        print(f"\nğŸ“ ç”Ÿæˆå¯¼å…¥è„šæœ¬: {filename}")
        
        # åªä¿ç•™æœ‰æ¡å½¢ç çš„æ•°æ®
        valid_drugs = [d for d in self.drugs if d.get('barcode')]
        
        if not valid_drugs:
            print("âŒ æ²¡æœ‰åŒ…å«æ¡å½¢ç çš„æ•°æ®")
            return
        
        script = """// æ‰¹é‡å¯¼å…¥äº¬ä¸œè¯ææ•°æ®åˆ°äº‘æ•°æ®åº“
// å…± """ + str(len(valid_drugs)) + """ æ¡æœ‰æ•ˆæ•°æ®ï¼ˆåŒ…å«æ¡å½¢ç ï¼‰

const db = wx.cloud.database()

const data = """ + json.dumps(valid_drugs, ensure_ascii=False, indent=2) + """

async function batchImport() {
  console.log('========================================')
  console.log('ğŸ“¦ å¼€å§‹æ‰¹é‡å¯¼å…¥äº¬ä¸œè¯ææ•°æ®')
  console.log('æ€»æ•°:', data.length)
  console.log('========================================')
  
  let successCount = 0
  let failCount = 0
  
  for (let i = 0; i < data.length; i++) {
    const item = data[i]
    
    try {
      // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
      const existing = await db.collection('barcode_mapping')
        .where({ barcode: item.barcode })
        .count()
      
      if (existing.total > 0) {
        console.log(`[${i+1}/${data.length}] â­ï¸ è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: ${item.name}`)
        continue
      }
      
      // æ·»åŠ åˆ°æ•°æ®åº“
      await db.collection('barcode_mapping').add({
        data: {
          barcode: item.barcode,
          drugName: item.name,
          specification: item.specification || '',
          unit: item.unit || 'ç›’',
          manufacturer: item.manufacturer || '',
          approvalNumber: item.approvalNumber || '',
          price: item.price || '',
          shop: item.shop || '',
          source: 'jd',
          createTime: db.serverDate()
        }
      })
      
      successCount++
      console.log(`[${i+1}/${data.length}] âœ… ${item.name}`)
      
    } catch (err) {
      failCount++
      console.error(`[${i+1}/${data.length}] âŒ ${item.name}:`, err.message)
    }
    
    // æ¯10æ¡å»¶è¿Ÿä¸€ä¸‹
    if ((i + 1) % 10 === 0) {
      await new Promise(resolve => setTimeout(resolve, 1000))
    }
  }
  
  console.log('========================================')
  console.log('âœ… å¯¼å…¥å®Œæˆ')
  console.log('æˆåŠŸ:', successCount)
  console.log('å¤±è´¥:', failCount)
  console.log('========================================')
}

// æ‰§è¡Œå¯¼å…¥
batchImport()
"""
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(script)
        
        print(f"âœ… è„šæœ¬å·²ç”Ÿæˆ")
        print(f"   åŒ…å« {len(valid_drugs)} æ¡æœ‰æ¡å½¢ç çš„æ•°æ®")
        print(f"   åœ¨å°ç¨‹åºå¼€å‘å·¥å…·æ§åˆ¶å°è¿è¡Œæ­¤è„šæœ¬å³å¯å¯¼å…¥")
    
    def close(self):
        """
        å…³é—­æµè§ˆå™¨
        """
        if self.driver:
            self.driver.quit()
            print("\nğŸ‘‹ æµè§ˆå™¨å·²å…³é—­")


def main():
    print("=" * 60)
    print("ğŸ•·ï¸  äº¬ä¸œåŒ»è¯æ•°æ®çˆ¬è™«")
    print("=" * 60)
    print()
    
    crawler = JDDrugCrawler()
    
    try:
        # æœç´¢å…³é”®è¯åˆ—è¡¨
        keywords = [
            "æ„Ÿå†’è¯",
            "æ¶ˆç‚è¯",
            "æ­¢å’³è¯",
            "æ­¢ç—›è¯",
            "é™å‹è¯",
            "é™ç³–è¯"
        ]
        
        # é€‰æ‹©æœç´¢å…³é”®è¯
        print("è¯·é€‰æ‹©æœç´¢å…³é”®è¯ï¼š")
        for i, kw in enumerate(keywords):
            print(f"  {i+1}. {kw}")
        print(f"  {len(keywords)+1}. è‡ªå®šä¹‰")
        
        choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-7): ").strip()
        
        if choice.isdigit() and 1 <= int(choice) <= len(keywords):
            keyword = keywords[int(choice) - 1]
        elif choice == str(len(keywords) + 1):
            keyword = input("è¯·è¾“å…¥å…³é”®è¯: ").strip()
        else:
            keyword = "æ„Ÿå†’è¯"
        
        # è¾“å…¥é¡µæ•°
        max_pages = input("çˆ¬å–é¡µæ•° (1-10ï¼Œé»˜è®¤3): ").strip()
        max_pages = int(max_pages) if max_pages.isdigit() else 3
        max_pages = min(max_pages, 10)  # æœ€å¤š10é¡µ
        
        # å¼€å§‹çˆ¬å–
        crawler.search_drugs(keyword=keyword, max_pages=max_pages)
        
        # æ˜¯å¦è·å–è¯¦æƒ…ï¼Ÿ
        if crawler.drugs:
            get_detail = input(f"\næ˜¯å¦è·å–è¯¦æƒ…ï¼ˆåŒ…æ‹¬æ¡å½¢ç ï¼‰ï¼Ÿ(y/n): ").strip().lower()
            if get_detail == 'y':
                crawler.batch_get_details()
        
        # ä¿å­˜æ•°æ®
        if crawler.drugs:
            crawler.save_to_csv()
            crawler.save_to_excel()
            crawler.generate_import_script()
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {str(e)}")
    
    finally:
        crawler.close()
    
    print("\nâœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()
